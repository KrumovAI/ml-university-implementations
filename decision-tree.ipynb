{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"decision-tree.ipynb","provenance":[{"file_id":"1v-0Byr_m7mUu1Gd_W1cer-TFEGcS9fB7","timestamp":1542366159727},{"file_id":"10Xth5hTSdrbkrGU2Ai4GdWA_zAE_BMzf","timestamp":1542361656524}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"RWg6PIEtvlSs","colab_type":"code","outputId":"be762337-27e1-4242-c0ac-a20fd8d255c5","executionInfo":{"status":"ok","timestamp":1571399819597,"user_tz":-180,"elapsed":9839,"user":{"displayName":"Emil Krumov","photoUrl":"","userId":"07398615179168096312"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["!apt-get install graphviz\n","!pip install graphviz\n","\n","!mkdir dot"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","graphviz is already the newest version (2.40.1-2).\n","0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.10.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qUl5QuVeXYcx","colab_type":"code","colab":{}},"source":["import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from matplotlib import rc\n","import unittest\n","import math\n","from sklearn import metrics\n","from sklearn.tree import export_graphviz\n","import IPython, graphviz, re\n","\n","%matplotlib inline\n","\n","sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n","\n","rcParams['figure.figsize'] = 12, 6\n","\n","RANDOM_SEED = 42\n","\n","np.random.seed(RANDOM_SEED)\n","\n","\n","def draw_tree(t, df, size=10, ratio=0.6, precision=0):\n","    \"\"\" Draws a representation of a random forest in IPython.\n","    Parameters:\n","    -----------\n","    t: The tree you wish to draw\n","    df: The data used to train the tree. This is used to get the names of the features.\n","    Source from: https://github.com/fastai/fastai/blob/e6b56de53f80d2b2d39037c82d3a23ce72507cd7/old/fastai/structured.py#L22\n","    \"\"\"\n","    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n","                      special_characters=True, rotate=True, precision=precision)\n","    IPython.display.display(graphviz.Source(re.sub('Tree {',\n","       f'Tree {{ size={size}; ratio={ratio}', s)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"odnKwqUctlXX","colab_type":"text"},"source":["# Load the data\n","\n","Data [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)"]},{"cell_type":"code","metadata":{"id":"ulPEgkKLZPLx","colab_type":"code","outputId":"f3bd77ec-8e52-414b-a6d2-619e714e1676","executionInfo":{"status":"ok","timestamp":1571399823896,"user_tz":-180,"elapsed":14109,"user":{"displayName":"Emil Krumov","photoUrl":"","userId":"07398615179168096312"}},"colab":{"base_uri":"https://localhost:8080/","height":210}},"source":["!wget https://raw.githubusercontent.com/Data-Science-FMI/ml-from-scratch-2019/master/data/house_prices_train.csv"],"execution_count":3,"outputs":[{"output_type":"stream","text":["--2019-10-18 11:57:01--  https://raw.githubusercontent.com/Data-Science-FMI/ml-from-scratch-2019/master/data/house_prices_train.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 460676 (450K) [text/plain]\n","Saving to: ‘house_prices_train.csv’\n","\n","\rhouse_prices_train.   0%[                    ]       0  --.-KB/s               \rhouse_prices_train. 100%[===================>] 449.88K  --.-KB/s    in 0.04s   \n","\n","2019-10-18 11:57:01 (12.1 MB/s) - ‘house_prices_train.csv’ saved [460676/460676]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uJV2KSJKZQ2Q","colab_type":"code","colab":{}},"source":["df_train = pd.read_csv('house_prices_train.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fwUmkYUStoz0","colab_type":"text"},"source":["# Decision trees"]},{"cell_type":"markdown","metadata":{"id":"wAoyCZdvstuf","colab_type":"text"},"source":["![](https://www.xoriant.com/blog/wp-content/uploads/2017/08/Decision-Trees-modified-1.png)\n","\n","Decision tree models can be used for both classification and regression. The algorithms for building trees breaks down a data set into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes. A decision node has two or more branches. Leaf node represents a classification or decision (used for regression). The topmost decision node in a tree which corresponds to the best predictor (most important feature) is called a root node. Decision trees can handle both categorical and numerical data."]},{"cell_type":"code","metadata":{"id":"0aGOfq3WZSh4","colab_type":"code","colab":{}},"source":["X = df_train[['OverallQual', 'GrLivArea', 'GarageCars']]\n","y = df_train['SalePrice']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RUWchJE7xPF4","colab_type":"text"},"source":["# Cost function\n","\n","Root Mean Squared Error:\n","\n","$$RMSE =  \\sqrt{\\frac{1}{m} \\sum_{i=1}^{m} (y^{(i)} - h(x^{(i)}))^2}$$"]},{"cell_type":"code","metadata":{"id":"pr2-tgH-xUg1","colab_type":"code","colab":{}},"source":["from sklearn.metrics import mean_squared_error\n","\n","def rmse(h, y):\n","  return math.sqrt(mean_squared_error(h, y)) # np.sum((y - h) ** (y - h)) / float(len(y))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VtZqDfiZuZaR","colab_type":"text"},"source":["# Using scikit-learn"]},{"cell_type":"code","metadata":{"id":"ZeK6jxjuuevJ","colab_type":"code","outputId":"3d03c831-833a-4ce4-ba4f-1a6380c2906e","executionInfo":{"status":"ok","timestamp":1571399855227,"user_tz":-180,"elapsed":45408,"user":{"displayName":"Emil Krumov","photoUrl":"","userId":"07398615179168096312"}},"colab":{"base_uri":"https://localhost:8080/","height":140}},"source":["from sklearn.ensemble import RandomForestRegressor\n","\n","reg = RandomForestRegressor(\n","  n_estimators=10000,\n","  bootstrap=False,\n","  random_state=RANDOM_SEED\n",")\n","\n","reg.fit(X, y)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=None,\n","                      max_features='auto', max_leaf_nodes=None,\n","                      min_impurity_decrease=0.0, min_impurity_split=None,\n","                      min_samples_leaf=1, min_samples_split=2,\n","                      min_weight_fraction_leaf=0.0, n_estimators=10000,\n","                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n","                      warm_start=False)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"6APmkksowMX6","colab_type":"code","outputId":"1f59ec6c-08f1-4dcd-8d4b-4d353cfc67b4","executionInfo":{"status":"ok","timestamp":1571399858656,"user_tz":-180,"elapsed":48819,"user":{"displayName":"Emil Krumov","photoUrl":"","userId":"07398615179168096312"}},"colab":{"base_uri":"https://localhost:8080/","height":596,"output_embedded_package_id":"15VMm_DHcaKGENqxuwONr0InNATYZvP-D"}},"source":["draw_tree(reg.estimators_[0], X, precision=2)"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"SVnU3NtMyg-0","colab_type":"code","outputId":"4977c4e9-84d3-45ef-f0dd-19382cdda0f9","executionInfo":{"status":"ok","timestamp":1571399860769,"user_tz":-180,"elapsed":50906,"user":{"displayName":"Emil Krumov","photoUrl":"","userId":"07398615179168096312"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["preds = reg.predict(X)\n","rmse(preds, y)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8634.6468023289"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"jThz0g-3uQHu","colab_type":"text"},"source":["# Decision Tree Implementation\n","\n","We're going to split our tree based on information gain. Concretely, we will try to split every feature in a way that both groups have as low standard deviation as possible. In that way we're going to minimize the RMSE."]},{"cell_type":"code","metadata":{"id":"pl7C-mu04spu","colab_type":"code","colab":{}},"source":["class Node:\n","  \n","  def __init__(self, x, y, idxs, min_leaf=5):\n","    self.x = x\n","    self.y = y\n","    self.idxs = idxs\n","    self.min_leaf = min_leaf\n","    \n","    self.row_count = len(idxs)\n","    self.col_count = x.shape[1]\n","    self.val = np.mean(y[idxs])\n","    self.score = float('inf')\n","    self.find_varsplit()\n","    \n","  def find_varsplit(self):\n","    for c in range(self.col_count):\n","      self.find_better_split(c)\n","      \n","    if self.is_leaf:\n","      return\n","    \n","    x = self.split_col\n","    lhs = np.nonzero(x <= self.split)[0]\n","    rhs = np.nonzero(x > self.split)[0]\n","    \n","    self.lhs = Node(self.x, self.y, self.idxs[lhs], self.min_leaf)\n","    self.rhs = Node(self.x, self.y, self.idxs[rhs], self.min_leaf)\n","  \n","  def find_better_split(self, var_idx):\n","    x, y = self.x.values[self.idxs, var_idx], self.y[self.idxs]\n","    \n","    for r in range(self.row_count):\n","      lhs = x <= x[r]\n","      rhs = x > x[r]\n","      \n","      if rhs.sum() < self.min_leaf or lhs.sum() < self.min_leaf:\n","        continue\n","        \n","      lhs_std = y[lhs].std()\n","      rhs_std = y[lhs].std()\n","      \n","      curr_score = lhs_std * lhs.sum() + rhs_std * rhs.sum() # weighted average\n","      \n","      if curr_score < self.score:\n","        self.var_idx = var_idx\n","        self.score = curr_score\n","        self.split = x[r]\n","    \n","  @property\n","  def is_leaf(self): return self.score == float('inf')\n","  \n","  @property\n","  def split_col(self): return self.x.values[self.idxs, self.var_idx]\n","  \n","  def predict(self, x):\n","    return np.array([self.predict_row(xi) for xi in x])\n","  \n","  def predict_row(self, xi):\n","    if self.is_leaf:\n","      return self.val\n","    \n","    n = self.lhs if xi[self.var_idx] <= self.split else self.rhs\n","    \n","    return n.predict_row(xi)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"az-uVislq4rr","colab_type":"code","colab":{}},"source":["class DecisionTreeRegressor:\n","  \n","  def fit(self, X, y, min_leaf=5):\n","    self.dtree = Node(X, y, np.array(np.arange(len(y))), min_leaf)\n","    return self\n","  \n","  def predict(self, X):\n","    return self.dtree.predict(X.values)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bo-WXSmDuTy3","colab_type":"text"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"id":"EOZ12otNsNE_","colab_type":"code","colab":{}},"source":["regressor = DecisionTreeRegressor().fit(X, y)\n","preds = regressor.predict(X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lEJASz_k5yxl","colab_type":"code","outputId":"383cf6dc-7d0e-48e2-927c-95c197261dd9","executionInfo":{"status":"ok","timestamp":1571399969546,"user_tz":-180,"elapsed":159652,"user":{"displayName":"Emil Krumov","photoUrl":"","userId":"07398615179168096312"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["metrics.r2_score(y, preds)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.847795933340548"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"OJmGr7Zr578G","colab_type":"code","outputId":"93e9426e-3d4e-4aa5-b1d5-502f9b34461a","executionInfo":{"status":"ok","timestamp":1571399969547,"user_tz":-180,"elapsed":159634,"user":{"displayName":"Emil Krumov","photoUrl":"","userId":"07398615179168096312"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["rmse(preds, y)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30982.557516311914"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"YpP0mfw40sUZ","colab_type":"text"},"source":["# Resources\n","\n","[Let’s Write a Decision Tree Classifier from Scratch](https://www.youtube.com/watch?v=LDRbO9a6XPU)"]}]}